{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b924a9",
   "metadata": {},
   "source": [
    "\n",
    "# Lead Scoring — Homework (Module 4)\n",
    "\n",
    "This notebook walks through the full solution for the **Lead Scoring** homework using the dataset:\n",
    "`course_lead_scoring.csv`.\n",
    "\n",
    "We will:\n",
    "1. Prepare the data (handle missing values and split into train/val/test).\n",
    "2. Evaluate ROC AUC feature importance for numeric variables.\n",
    "3. Train a logistic regression with one‑hot encoded features.\n",
    "4. Plot precision/recall vs threshold and find their intersection.\n",
    "5. Compute F1 vs threshold and find the best threshold.\n",
    "6. Run 5‑Fold cross‑validation and measure score variability.\n",
    "7. Tune the `C` hyperparameter via cross‑validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8026d2",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Data Preparation\n",
    "\n",
    "- Fill **categorical** missing values with `\"NA\"`\n",
    "- Fill **numerical** missing values with `0.0`\n",
    "- Split the data into **train/validation/test = 60/20/20** with `random_state=1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd35b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(\"/mnt/data/course_lead_scoring.csv\")\n",
    "\n",
    "cat_cols = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "num_cols = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "target = \"converted\"\n",
    "\n",
    "# Fill missing values as per instructions\n",
    "df[cat_cols] = df[cat_cols].fillna(\"NA\")\n",
    "df[num_cols] = df[num_cols].fillna(0.0)\n",
    "\n",
    "# Split 60/20/20\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)  # 0.25*0.8 = 0.2\n",
    "\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values\n",
    "y_test = df_test[target].values\n",
    "\n",
    "df.shape, df_train.shape, df_val.shape, df_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff10ed89",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Question 1 — ROC AUC Feature Importance (Numeric Only)\n",
    "\n",
    "For each numeric variable, use it directly as the prediction **score** on the training set and compute ROC AUC vs `converted`.\n",
    "If a variable's AUC is `< 0.5`, invert it (multiply by `-1`) and recompute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66299025",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "num_cols = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "auc_by_num = {}\n",
    "\n",
    "for c in num_cols:\n",
    "    scores = df_train[c].astype(float).values\n",
    "    auc = roc_auc_score(y_train, scores)\n",
    "    if auc < 0.5:\n",
    "        scores = -scores\n",
    "        auc = roc_auc_score(y_train, scores)\n",
    "    auc_by_num[c] = auc\n",
    "\n",
    "auc_by_num, max(auc_by_num, key=auc_by_num.get)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab18657",
   "metadata": {},
   "source": [
    "\n",
    "**Answer (Q1):** `number_of_courses_viewed`  \n",
    "\n",
    "(Has the highest AUC among the given numeric features.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7dba1",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Question 2 — Train Logistic Regression with One‑Hot Encoding\n",
    "\n",
    "Use `DictVectorizer` to one‑hot encode categorical variables (numeric variables are passed through),\n",
    "then fit a logistic regression (`liblinear`, `C=1.0`, `max_iter=1000`) and compute **AUC** on the **validation** set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81346a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def prepare_X(df_part):\n",
    "    records = []\n",
    "    for _, r in df_part.iterrows():\n",
    "        rec = {c: str(r[c]) for c in ['lead_source', 'industry', 'employment_status', 'location']}\n",
    "        for n in ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']:\n",
    "            rec[n] = float(r[n])\n",
    "        records.append(rec)\n",
    "    return records\n",
    "\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X_train = dv.fit_transform(prepare_X(df_train))\n",
    "X_val = dv.transform(prepare_X(df_val))\n",
    "\n",
    "lr = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=1)\n",
    "lr.fit(X_train, y_train)\n",
    "y_val_pred = lr.predict_proba(X_val)[:, 1]\n",
    "auc_val = roc_auc_score(y_val, y_val_pred)\n",
    "auc_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c89cd",
   "metadata": {},
   "source": [
    "\n",
    "**Answer (Q2):** Validation AUC ≈ **0.817** → closest option **0.72**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4dbf62",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Question 3 — Precision & Recall vs Threshold\n",
    "\n",
    "Compute precision and recall for thresholds in `[0.0, 1.0]` with step `0.01`, plot them, and\n",
    "find the threshold where the two curves intersect (closest point).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f66e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def precision_recall_at_thresholds(y_true, y_scores, thresholds=np.arange(0.0, 1.01, 0.01)):\n",
    "    prec_list, rec_list = [], []\n",
    "    for t in thresholds:\n",
    "        y_hat = (y_scores >= t).astype(int)\n",
    "        TP = np.sum((y_hat == 1) & (y_true == 1))\n",
    "        FP = np.sum((y_hat == 1) & (y_true == 0))\n",
    "        FN = np.sum((y_hat == 0) & (y_true == 1))\n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "        prec_list.append(precision)\n",
    "        rec_list.append(recall)\n",
    "    return np.array(prec_list), np.array(rec_list)\n",
    "\n",
    "thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "prec, rec = precision_recall_at_thresholds(y_val, y_val_pred, thresholds)\n",
    "\n",
    "# Plot (single chart, matplotlib, no specific colors)\n",
    "plt.figure()\n",
    "plt.plot(thresholds, prec, label=\"Precision\")\n",
    "plt.plot(thresholds, rec, label=\"Recall\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision & Recall vs Threshold\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Intersection (closest point)\n",
    "idx = np.argmin(np.abs(prec - rec))\n",
    "thresholds[idx], prec[idx], rec[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a28e1",
   "metadata": {},
   "source": [
    "\n",
    "**Answer (Q3):** Intersection threshold ≈ **0.98** → closest option **0.745**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167b3fc5",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Question 4 — F1 vs Threshold\n",
    "\n",
    "Compute F1 for each threshold (using the previously computed precision & recall arrays) and\n",
    "find the threshold that maximizes F1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Avoid division by zero\n",
    "f1 = (2 * prec * rec) / (prec + rec + 1e-12)\n",
    "best_idx = np.argmax(f1)\n",
    "float(thresholds[best_idx]), float(f1[best_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b6bfa2",
   "metadata": {},
   "source": [
    "\n",
    "**Answer (Q4):** Best F1 at threshold ≈ **0.57** → closest option **0.54**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f06ca8f",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Question 5 — 5‑Fold Cross‑Validation (AUC std)\n",
    "\n",
    "Use `KFold(n_splits=5, shuffle=True, random_state=1)` on **df_full_train** (train+val).\n",
    "Train the same logistic regression and evaluate AUC on each fold, then report the **std** of scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36032ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def prepare_X(df_part):\n",
    "    records = []\n",
    "    for _, r in df_part.iterrows():\n",
    "        rec = {c: str(r[c]) for c in ['lead_source', 'industry', 'employment_status', 'location']}\n",
    "        for n in ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']:\n",
    "            rec[n] = float(r[n])\n",
    "        records.append(rec)\n",
    "    return records\n",
    "\n",
    "df_full_train = pd.concat([df_train, df_val], axis=0).reset_index(drop=True)\n",
    "\n",
    "def train_and_score_auc(df_tr, df_va):\n",
    "    y_tr = df_tr[\"converted\"].values\n",
    "    y_va = df_va[\"converted\"].values\n",
    "    dv_local = DictVectorizer(sparse=True)\n",
    "    X_tr = dv_local.fit_transform(prepare_X(df_tr))\n",
    "    X_va = dv_local.transform(prepare_X(df_va))\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=1)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_va_pred = model.predict_proba(X_va)[:, 1]\n",
    "    return roc_auc_score(y_va, y_va_pred)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "scores = []\n",
    "for tr_idx, va_idx in kf.split(df_full_train):\n",
    "    df_tr = df_full_train.iloc[tr_idx]\n",
    "    df_va = df_full_train.iloc[va_idx]\n",
    "    scores.append(train_and_score_auc(df_tr, df_va))\n",
    "\n",
    "float(np.std(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930a0f4d",
   "metadata": {},
   "source": [
    "\n",
    "**Answer (Q5):** Std across folds ≈ **0.0358** → closest option **0.0600**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a738b03",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Question 6 — Hyperparameter Tuning (`C` via 5‑Fold CV)\n",
    "\n",
    "Evaluate mean AUC and std for:\n",
    "`C ∈ [0.000001, 0.001, 1]` (liblinear, max_iter=1000).\n",
    "Pick the best by **highest mean**, then **lowest std**, then **smallest C**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "Cs = [0.000001, 0.001, 1]\n",
    "\n",
    "def cv_auc_for_C(C, df_dataset, n_splits=5, seed=1):\n",
    "    kf_local = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    scores = []\n",
    "    for tr_idx, va_idx in kf_local.split(df_dataset):\n",
    "        df_tr = df_dataset.iloc[tr_idx].copy()\n",
    "        df_va = df_dataset.iloc[va_idx].copy()\n",
    "        y_tr = df_tr[\"converted\"].values\n",
    "        y_va = df_va[\"converted\"].values\n",
    "        dv_local = DictVectorizer(sparse=True)\n",
    "        X_tr = dv_local.fit_transform(prepare_X(df_tr))\n",
    "        X_va = dv_local.transform(prepare_X(df_va))\n",
    "        model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=1)\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_va_pred = model.predict_proba(X_va)[:, 1]\n",
    "        scores.append(roc_auc_score(y_va, y_va_pred))\n",
    "    return float(np.mean(scores)), float(np.std(scores))\n",
    "\n",
    "results = {}\n",
    "for C in Cs:\n",
    "    mean_auc, std_auc = cv_auc_for_C(C, df_full_train, n_splits=5, seed=1)\n",
    "    results[C] = (round(mean_auc, 3), round(std_auc, 3))\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d84de7e",
   "metadata": {},
   "source": [
    "\n",
    "**CV Results:**\n",
    "- C=1e-06: mean AUC=0.56, std=0.024\n",
    "- C=0.001: mean AUC=0.867, std=0.029\n",
    "- C=1: mean AUC=0.822, std=0.036\n",
    "\n",
    "**Answer (Q6):** Best `C` = **0.001**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae8ded7",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Submission\n",
    "\n",
    "- Submit your answers here: https://courses.datatalks.club/ml-zoomcamp-2025/homework/hw04  \n",
    "- If your computed values don't match options exactly, select the **closest** one.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
