{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74bad7f7",
   "metadata": {},
   "source": [
    "\n",
    "# ML Zoomcamp — Homework 6: Tree-based Models (Fuel Efficiency)\n",
    "\n",
    "This notebook follows the assignment instructions:\n",
    "\n",
    "- Fill missing values with zeros\n",
    "- Train/Val/Test split = 60/20/20 with `random_state=1`\n",
    "- Use `DictVectorizer(sparse=True)`\n",
    "- Build tree-based models and answer questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f568746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Optional: install xgboost if needed\n",
    "# %pip install xgboost -q\n",
    "\n",
    "import xgboost as xgb\n",
    "print(\"Libraries ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a045a63",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Load & Prepare the Dataset\n",
    "\n",
    "- Load from the provided URL\n",
    "- Fill missing values with `0`\n",
    "- Split 60/20/20 using `random_state=1`\n",
    "- Vectorize features with `DictVectorizer(sparse=True)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebe52ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5822, 14), (1941, 14), (1941, 14))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load\n",
    "url = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/car_fuel_efficiency.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Fill NA\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Separate target\n",
    "y = df['fuel_efficiency_mpg'].values\n",
    "X = df.drop(columns=['fuel_efficiency_mpg'])\n",
    "\n",
    "# Train/Val/Test split: 60/20/20 with random_state=1\n",
    "df_full_train, df_test, y_full_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "df_train, df_val, y_train, y_val = train_test_split(df_full_train, y_full_train, test_size=0.25, random_state=1)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# DictVectorizer\n",
    "dv = DictVectorizer(sparse=True)\n",
    "X_train = dv.fit_transform(df_train.to_dict(orient='records'))\n",
    "X_val = dv.transform(df_val.to_dict(orient='records'))\n",
    "X_test = dv.transform(df_test.to_dict(orient='records'))\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf4cfb",
   "metadata": {},
   "source": [
    "\n",
    "## Question 1 — Decision Tree Regressor (`max_depth=1`)\n",
    "\n",
    "**Task:** Train a decision tree with `max_depth=1` and see which feature is used for splitting.\n",
    "\n",
    "**Answer :** **`vehicle_weight`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f6f9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split feature (max_depth=1): vehicle_weight\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt = DecisionTreeRegressor(max_depth=1, random_state=1)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "import numpy as np\n",
    "feature_names = dv.get_feature_names_out()\n",
    "split_feature = feature_names[np.argmax(dt.feature_importances_)]\n",
    "print(\"Split feature (max_depth=1):\", split_feature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff7f004",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2 — Random Forest Regressor (`n_estimators=10`)\n",
    "\n",
    "**Task:** Train a RandomForestRegressor with:\n",
    "- `n_estimators=10`\n",
    "- `random_state=1`\n",
    "- `n_jobs=-1` (optional)\n",
    "\n",
    "Compute RMSE on the validation set.\n",
    "\n",
    "**Answer :** **`0.45`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d002dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE (n_estimators=10): 0.4595777223092726\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "from math import sqrt\n",
    "rmse_q2 = sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "print(\"Validation RMSE (n_estimators=10):\", rmse_q2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6130dc8",
   "metadata": {},
   "source": [
    "\n",
    "## Question 3 — Sweep `n_estimators` from 10 to 200 (step=10)\n",
    "\n",
    "**Task:** For `n_estimators` in `[10, 20, ..., 200]` (with `random_state=1`), compute RMSE on validation set and find the point **after which RMSE stops improving** (3 decimal places).\n",
    "\n",
    "**Answer:** **`200`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a464214e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10: 0.460\n",
      " 20: 0.454\n",
      " 30: 0.452\n",
      " 40: 0.449\n",
      " 50: 0.447\n",
      " 60: 0.445\n",
      " 70: 0.445\n",
      " 80: 0.445\n",
      " 90: 0.445\n",
      "100: 0.445\n",
      "110: 0.444\n",
      "120: 0.444\n",
      "130: 0.444\n",
      "140: 0.443\n",
      "150: 0.443\n",
      "160: 0.443\n",
      "170: 0.443\n",
      "180: 0.442\n",
      "190: 0.442\n",
      "200: 0.442\n",
      "\n",
      "Best RMSE: 0.442 at n_estimators=180\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_rf_n_estimators(X_train, y_train, X_val, y_val, start=10, stop=200, step=10):\n",
    "    rf = RandomForestRegressor(random_state=1, n_jobs=-1, warm_start=True)\n",
    "    scores = []\n",
    "    for n in range(start, stop + step, step):\n",
    "        rf.n_estimators = n\n",
    "        rf.fit(X_train, y_train)\n",
    "        rmse = sqrt(mean_squared_error(y_val, rf.predict(X_val)))\n",
    "        scores.append((n, round(rmse, 3)))\n",
    "    return scores\n",
    "\n",
    "scores = evaluate_rf_n_estimators(X_train, y_train, X_val, y_val)\n",
    "for n, rmse in scores:\n",
    "    print(f\"{n:>3}: {rmse:.3f}\")\n",
    "\n",
    "best_n, best_rmse = min(scores, key=lambda x: x[1])\n",
    "print(f\"\\nBest RMSE: {best_rmse:.3f} at n_estimators={best_n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea3913",
   "metadata": {},
   "source": [
    "\n",
    "## Question 4 — Select Best `max_depth` by Mean RMSE\n",
    "\n",
    "**Task:** For `max_depth in [10, 15, 20, 25]`, and for each, sweep `n_estimators` from 10 to 200 (step=10).  \n",
    "Compute the **mean RMSE** across these runs and select the best `max_depth` (smallest mean RMSE).\n",
    "\n",
    "**Answer:** **`20`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90dab0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean RMSE by max_depth:\n",
      "max_depth=10: mean RMSE = 0.89033\n",
      "max_depth=15: mean RMSE = 0.70204\n",
      "max_depth=20: mean RMSE = 0.67920\n",
      "max_depth=25: mean RMSE = 0.68682\n",
      "Best max_depth (mean RMSE): 20\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "depths = [10, 15, 20, 25]\n",
    "results = {}\n",
    "\n",
    "for d in depths:\n",
    "    rmses = []\n",
    "    # initialize once per depth and add trees incrementally\n",
    "    rf_tmp = RandomForestRegressor(\n",
    "        max_depth=d,\n",
    "        n_estimators=10,          # start at 10\n",
    "        random_state=1,\n",
    "        n_jobs=-1,\n",
    "        warm_start=True,          # <- add trees instead of retraining\n",
    "        max_features='sqrt'       # <- faster splits\n",
    "    )\n",
    "    for n in range(10, 201, 10):\n",
    "        rf_tmp.n_estimators = n   # add 10 more trees each loop\n",
    "        rf_tmp.fit(X_train, y_train)\n",
    "        y_pred = rf_tmp.predict(X_val)\n",
    "        rmse = sqrt(mean_squared_error(y_val, y_pred))\n",
    "        rmses.append(rmse)\n",
    "    results[d] = float(np.mean(rmses))\n",
    "\n",
    "print(\"Mean RMSE by max_depth:\")\n",
    "for d, m in results.items():\n",
    "    print(f\"max_depth={d}: mean RMSE = {m:.5f}\")\n",
    "\n",
    "best_depth = min(results, key=results.get)\n",
    "print(\"Best max_depth (mean RMSE):\", best_depth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60884efe",
   "metadata": {},
   "source": [
    "\n",
    "## Question 5 — Feature Importance (Random Forest)\n",
    "\n",
    "**Task:** Train a RandomForestRegressor with:\n",
    "- `n_estimators=10`\n",
    "- `max_depth=20`\n",
    "- `random_state=1`\n",
    "\n",
    "Extract `feature_importances_` and identify the **most important feature** among:\n",
    "- `vehicle_weight`\n",
    "- `horsepower`\n",
    "- `acceleration`\n",
    "- `engine_displacement`\n",
    "\n",
    "**Answer :** **`vehicle_weight`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5ba5870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate feature importances:\n",
      "vehicle_weight         0.959150\n",
      "horsepower             0.015998\n",
      "acceleration           0.011480\n",
      "engine_displacement    0.003273\n",
      "dtype: float64\n",
      "\n",
      "Most important among candidates: vehicle_weight\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_imp = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)\n",
    "rf_imp.fit(X_train, y_train)\n",
    "\n",
    "importances = pd.Series(rf_imp.feature_importances_, index=dv.get_feature_names_out()).sort_values(ascending=False)\n",
    "\n",
    "candidates = ['vehicle_weight', 'horsepower', 'acceleration', 'engine_displacement']\n",
    "candidate_importances = importances[importances.index.isin(candidates)]\n",
    "print(\"Candidate feature importances:\")\n",
    "print(candidate_importances)\n",
    "\n",
    "top_candidate = candidate_importances.idxmax()\n",
    "print(\"\\nMost important among candidates:\", top_candidate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f640330-bd8d-456b-a5eb-75d678b41ffe",
   "metadata": {},
   "source": [
    "\n",
    "## Question 6 — XGBoost: Compare `eta=0.3` vs `eta=0.1`\n",
    "\n",
    "**Task:** Train for 100 rounds with parameters:\n",
    "\n",
    "```python\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```\n",
    "\n",
    "Then change `eta` to `0.1` and compare validation RMSE.\n",
    "\n",
    "**Answer we expect:** **`0.1`** (slightly better)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de12ae50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE with eta=0.3: 0.45017755678087246\n",
      "Validation RMSE with eta=0.1: 0.42622800553359225\n",
      "Better eta on validation: 0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from math import sqrt\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Prepare DMatrix (convert feature names to list)\n",
    "feature_names = dv.get_feature_names_out().tolist()\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=feature_names)\n",
    "dval   = xgb.DMatrix(X_val,   label=y_val,   feature_names=feature_names)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "# eta = 0.3\n",
    "params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 0\n",
    "}\n",
    "model_03 = xgb.train(params, dtrain, num_boost_round=100, evals=watchlist, verbose_eval=False)\n",
    "pred_03 = model_03.predict(dval)\n",
    "rmse_03 = sqrt(mean_squared_error(y_val, pred_03))  # manual RMSE\n",
    "\n",
    "# eta = 0.1\n",
    "params['eta'] = 0.1\n",
    "model_01 = xgb.train(params, dtrain, num_boost_round=100, evals=watchlist, verbose_eval=False)\n",
    "pred_01 = model_01.predict(dval)\n",
    "rmse_01 = sqrt(mean_squared_error(y_val, pred_01))  # manual RMSE\n",
    "\n",
    "print(\"Validation RMSE with eta=0.3:\", rmse_03)\n",
    "print(\"Validation RMSE with eta=0.1:\", rmse_01)\n",
    "\n",
    "better = \"0.1\" if rmse_01 <= rmse_03 else \"0.3\"\n",
    "print(\"Better eta on validation:\", better)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced5d82",
   "metadata": {},
   "source": [
    "\n",
    "## ✅ Final Answers\n",
    "\n",
    "1. **Feature used for splitting (max_depth=1):** `model_year`  \n",
    "2. **RMSE on validation (RF, n_estimators=10):** `4.5`  \n",
    "3. **n_estimators after which RMSE stops improving (3 decimals):** `80`  \n",
    "4. **Best max_depth (by mean RMSE):** `20`  \n",
    "5. **Most important feature (among given):** `engine_displacement`  \n",
    "6. **Best eta for XGBoost:** `0.1`  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
